{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, utils, parsing\n",
    "from gensim.test.utils import datapath\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function loads previously saved model \n",
    "lda = models.LdaModel.load('lk-ldamodelmallet-new.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load topics; for now just load the top 10 words\n",
    "# note that for tome, we'd need to replace num_words=10 with num_words=10000 <-- !!!!\n",
    "topics = lda.show_topics(num_topics=100, num_words=10, formatted=False)\n",
    "\n",
    "# print the first two topic lines just to be sure\n",
    "for i in range(2):\n",
    "   print(topics[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics_file = \"./topic-data/allpapers-doctopics.txt\"\n",
    "\n",
    "# print the first line\n",
    "with open(doc_topics_file) as myfile:\n",
    "    head = [next(myfile) for x in range(1)]\n",
    "print(head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_file = \"./topic-data/allpapers-topics.txt\"\n",
    "\n",
    "# print the first 2 lines\n",
    "with open(topics_file) as myfile:\n",
    "    head = [next(myfile) for x in range(2)]\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get top 10 words associated with each topic, and print to a file for future reference\n",
    "\n",
    "cleantopics = \"\"\n",
    "\n",
    "for topic in topics:\n",
    "    wordpairs = topic[1]\n",
    "    words = []\n",
    "    wordstring = \"\"\n",
    "    \n",
    "    for wordpair in wordpairs:\n",
    "        words.append(wordpair[0])\n",
    "    for word in words:\n",
    "        wordstring += word + \",\"\n",
    "    cleantopics += str(topic[0]) + \",\" + wordstring + \"\\n\"\n",
    "\n",
    "with open(\"./topic-data/20190204-cleantopics-new.csv\",\"w\") as myfile:\n",
    "    myfile.write(cleantopics)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now chunk topic counts by newspaper\n",
    "# need to end up with csv in format TITLE, TOTALTOPIC0SCORE, TOTALTOPIC1SCORE, TOTALTOPIC2SCORE, ETC.\n",
    "# the topic scores come from doc_topics_file\n",
    "# but need to cross reference w/ \"aa-docMetadata-new.csv\" file to figure out the newspaper that the doc comes from\n",
    "\n",
    "# first, assign metadata file\n",
    "\n",
    "metadata_file = \"./metadata/aa-docMetadata-new.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first need to figure out number/title of all newspapers\n",
    "\n",
    "# let's see what the metadata file looks like\n",
    "\n",
    "# print the first 2 lines\n",
    "with open(metadata_file) as myfile:\n",
    "    head = [next(myfile) for x in range(2)]\n",
    "print(head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, split by \",\" and then second item by \"/\"\n",
    "metadata = []\n",
    "\n",
    "with open(metadata_file, newline=\"\\n\") as csvfile:\n",
    "    metadata = list(csv.reader(csvfile))\n",
    "\n",
    "newspapers = []\n",
    "    \n",
    "for doc in metadata:\n",
    "    docID = doc[0]\n",
    "    titleString = doc[1]\n",
    "    titleParts = titleString.split(\"/\")\n",
    "    title = titleParts[0]\n",
    "    \n",
    "    if title not in newspapers:\n",
    "        newspapers.append(title)\n",
    "        \n",
    "print(newspapers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we've got a list of all the newspaper titles, so let's start counting! \n",
    "# rememeber, goal is aggregate topic scores for each newspaper \n",
    "\n",
    "# create new dataframe w/ newspapers as index, 100 cols, initialized to 0\n",
    "df = pd.DataFrame(0, index=newspapers, columns=range(100))\n",
    "\n",
    "df = df.astype('float')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the giant doc_topics file and go line by line\n",
    "with open(doc_topics_file) as myfile:\n",
    "    for i, line in enumerate(myfile):\n",
    "        # figure out which newspaper it belongs to; \n",
    "        # i is same as docID in metadata file \n",
    "        print(\"Looking up topic values for doc\",i)\n",
    "        doc_metadata = metadata[i]\n",
    "        titleString = doc_metadata[1]\n",
    "        titleParts = titleString.split(\"/\")\n",
    "        title = titleParts[0]\n",
    "   \n",
    "        # then, get the topic scores\n",
    "        items = line.split(\",\")\n",
    "        topic_scores = items[1::2]\n",
    "\n",
    "        # now add to correct topic count for newspaper\n",
    "    \n",
    "        for j, score in enumerate(topic_scores):  \n",
    "            score = score.strip(' ()[]\\n' )\n",
    "            score = float(score)\n",
    "            df.loc[title].at[j] += score          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to csv\n",
    "\n",
    "df.to_csv(\"20190204-newspaper-topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
